p8105_hw6_xl3214
================
Xuan Lu
2023-11-29

## Problem 1: The Homocide Dataset by Washington Post

### Step 1: Data Import and Preparation for Analysis

``` r
q1_raw <- read.csv(file = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv", 
                   na = c("", "NA", "Unknown"))
```

The raw data has 12 variables and 52179 observations. Variables include:
*uid, reported_date, victim_last, victim_first, victim_race, victim_age,
victim_sex, city, state, lat, lon, disposition*.

``` r
q1_for_analysis <- q1_raw |>
  # Create city_state variable in the format of "City, State"
  mutate(city_state = paste(city, state, sep = ", "), 
         # victim_age needs to be numeric
         victim_age = as.numeric(victim_age), 
         # Create binary variable indicating whether the homicide is solved
         resolved = factor(ifelse(disposition == "Closed by arrest", 1, 0),
                           levels = c(0, 1),
                           labels = c("No", "Yes"),
                           ordered = TRUE)) |>
  # Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race
  # Omit Tulsa, AL – this is a data entry mistake
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) |>
  # Limit analysis to victim_race is white or black
  filter(victim_race %in% c("White", "Black")) |>
  select(city_state, resolved, victim_age, victim_sex, victim_race)
```

After data cleaning and validation, which excludes cities Dallas, TX;
Phoenix, AZ; Kansas City, MO; and Tulsa, AL, and limiting the
victim_race to only black or white, the dataset pertained to analysis
stage includes 5 variables and 39693 observations.

### Step 2: Fit Logistic Regression for Baltimore, MD

Fit a logistic regression model for the city of Baltimore, MD using
`glm()`, with the binary variable indicating whether the homicide is
solved as the outcome, and victim age, sex, and race as predictors. Use
`broom::tidy()` to extract the model estimates and confidence intervals,
focusing on the adjusted odds ratio for male vs. female victims.

``` r
model_baltimore <- q1_for_analysis |>
  # Filter the dataset to include only rows where city_state is "Baltimore, MD"
  filter(city_state == "Baltimore, MD") |>
  # Fit a logistic regression model with resolved as the response variable and victim_age, victim_sex, and victim_race as predictors
  glm(resolved ~ victim_age + victim_sex + victim_race, 
                       data = _, family = "binomial") |>
  # Use broom::tidy to convert the glm model object into a tidy dataframe and calculate confidence intervals
  broom::tidy(conf.int = TRUE) |>
  # Filter the results to keep only the row for the term "victim_sexMale"
  filter(term == "victim_sexMale") |>
  # Calculate the odds ratio and its confidence intervals by exponentiating the estimates
  mutate(OR = exp(estimate),
         OR_lower_ci = exp(conf.low),
         OR_upper_ci = exp(conf.high),
         p_value = p.value) |>
  # Select only the relevant columns for the final output
  select(term, OR, OR_lower_ci, OR_upper_ci, p_value)
```

The odds of the homicide being solved for male victims is estimated to
be 0.4255117 times that of female victims, adjusting for victim age and
race. A reasonable (alpha = 0.05) range of estimates for the true OR is
between 0.3241908 and 0.5575508. The p-value is 6.2551188^{-10},
indicating a statistically significant association between victim’s sex
and the resolution of the homicide.

### Step 3: Logistic Regression for Each City and Dataframe with Estimated ORs and CIs

Apply `glm()` to each city in the dataset to get the adjusted odds ratio
for male vs. female victims using `tidyverse::nest()`, `purrr::map()`,
and `tidyverse::unnest()`.

``` r
model_all_cities <- q1_for_analysis |>
  # the data is being grouped by city_state and stored in "data"
  nest(data = -city_state) |>
  # fit the glm model for each nested dataframe
  mutate(models = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, 
                                 family = "binomial", data = .))) |>
  # tidy the glm models and calculate ORs and CIs
  mutate(tidy_models = map(models, ~broom::tidy(.x, conf.int = TRUE))) |>
  # extract only the rows corresponding to the term "victim_sexMale"
  mutate(tidy_models = map(tidy_models, ~filter(.x, term == "victim_sexMale"))) |>
  # calculate the odds ratios and confidence intervals
  mutate(tidy_models = map(tidy_models, ~mutate(.x, 
                                                OR = exp(estimate),
                                                OR_lower_ci = exp(conf.low),
                                                OR_upper_ci = exp(conf.high), 
                                                p_value = p.value))) |>
  # remove the columns that are no longer needed
  select(-data, -models) |>
  # unnest the tidy_models to get a flat dataframe
  unnest(cols = tidy_models) |>
  # select the final columns of interest
  select(city_state, term, OR, OR_lower_ci, OR_upper_ci, p_value)

model_all_cities |>
  arrange(desc(OR)) |> 
  slice(1:5) |>
  knitr::kable(digits = 3)
```

| city_state      | term           |    OR | OR_lower_ci | OR_upper_ci | p_value |
|:----------------|:---------------|------:|------------:|------------:|--------:|
| Albuquerque, NM | victim_sexMale | 1.767 |       0.825 |       3.762 |   0.139 |
| Stockton, CA    | victim_sexMale | 1.352 |       0.626 |       2.994 |   0.447 |
| Fresno, CA      | victim_sexMale | 1.335 |       0.567 |       3.048 |   0.496 |
| Nashville, TN   | victim_sexMale | 1.034 |       0.681 |       1.556 |   0.873 |
| Richmond, VA    | victim_sexMale | 1.006 |       0.483 |       1.994 |   0.987 |

Based on the output table, Albuquerque, NM has the highest odds ratio
when comparing victims whose sex is male to those whose sex is female.
With a p-value of 0.139, however, we do not have sufficient evidence to
conclude that the odds of resolving the homicide is statistically higher
among males than females in Albuquerque, NM, after adjusting for victim
age and race.

### Step 4: Plotting the Results

``` r
# Start with the model_all_cities dataset
model_all_cities |> 
  # Initialize a ggplot with city_state on the x-axis and OR on the y-axis. Cities are reordered by OR for a meaningful display.
  ggplot(aes(x = fct_reorder(city_state, OR), y = OR)) +
  # Add points to the plot for each city's OR value.
  geom_point() +
  # Add vertical error bars for each point to represent the confidence interval of the OR, with a specified width.
  geom_errorbar(aes(ymin = OR_lower_ci, ymax = OR_upper_ci), width = 0.2) +
  # Flip the coordinates to have cities on the y-axis and OR on the x-axis for easier reading of long city names.
  coord_flip() +
  # Add labels to the x and y axes, and a title to the plot.
  labs(x = "City", y = "Odds Ratio (Male vs Female Victims, reference = Female)",
       title = "Adjusted Odds Ratios for Solving Homicides by City")
```

![](p8105_hw6_xl3214_files/figure-gfm/Q1-plotting%20of%20ORs%20for%20all%20cities-1.png)<!-- -->

## Problem 2: NYC Central Park Weather

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: /Users/kristal99/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-11-28 16:40:03.620223 (8.544)

    ## file min/max dates: 1869-01-01 / 2023-11-30

### Steps:

- **Bootstrap Sampling:** Generate 5000 bootstrap samples of the
  dataset.
- **Fit Linear Regression:** For each sample, fit a linear regression
  model with *tmax* as the response variable and *tmin* and *prcp* as
  the predictors.
- **Extract R-square:** Use `broom::glance()` to extract the R-square
  value from each fitted model.
- **Calculate log(β_tmin x β_prcp):** Use `broom::tidy()` to get the
  regression coefficients from each model, then calculate the log
  product of the *tmin* and *prcp* coefficients.
- **Plot Distributions:** Plot the distributions of the 5000 R-square
  values and the 5000 log(β_hat_1 \* β_hat_2) values.
- **Calculate Confidence Intervals:** Determine the 2.5th and 97.5th
  percentiles of the bootstrap estimates to find the 95% confidence
  intervals for both statistics.

``` r
set.seed(123)  # For reproducibility of bootstrap samples

# Define the bootstrap function
bootstrap_sample <- function(df) {
  sample_indices <- sample(seq_len(nrow(df)), size = nrow(df), replace = TRUE)
  sample_df <- df[sample_indices, ]
  
  fit <- lm(tmax ~ tmin + prcp, data = sample_df)
  glance_stats <- glance(fit)
  tidy_stats <- tidy(fit)
  
  # Extract R-squared
  r_squared <- glance_stats[["r.squared"]]
  
  # Compute the log product of tmin and prcp coefficients
  coef_tmin <- tidy_stats |>
    filter(term == "tmin") |>
    pull(estimate)
  coef_prcp <- tidy_stats |>
    filter(term == "prcp") |>
    pull(estimate)
  # Handle cases where the product might be non-positive
  log_product <- ifelse(coef_tmin * coef_prcp > 0, log(coef_tmin * coef_prcp), NA)
  
  return(list(r_squared = r_squared, log_product = log_product))
}

# Generate bootstrap samples and compute statistics for each
bootstrap_results <- replicate(5000, bootstrap_sample(weather_df), simplify = FALSE) 
# Convert the list of bootstrap results into a data frame
bootstrap_results_df <- do.call(rbind.data.frame, bootstrap_results)

# Histogram of R^2
hist(bootstrap_results_df[, "r_squared"], main = "Histogram of R^2", 
     xlab = "R^2", breaks = 20, col = 'blue')
```

![](p8105_hw6_xl3214_files/figure-gfm/Q2-bootstrap%20sampling%20and%20plot-1.png)<!-- -->

``` r
# QQ-plot of R^2
qqnorm(bootstrap_results_df[, "r_squared"], main = "QQ-Plot of R^2")
qqline(bootstrap_results_df[, "r_squared"], col = 'red')
```

![](p8105_hw6_xl3214_files/figure-gfm/Q2-bootstrap%20sampling%20and%20plot-2.png)<!-- -->

``` r
# Histogram of log(beta_tmin * beta_prcp)
hist(bootstrap_results_df[, "log_product"], main = "Histogram of log(beta_tmin * beta_prcp)", 
     xlab = "log(beta_tmin * beta_prcp)", breaks = 20, col = 'blue')
```

![](p8105_hw6_xl3214_files/figure-gfm/Q2-bootstrap%20sampling%20and%20plot-3.png)<!-- -->

``` r
# QQ-plot of log(beta_tmin * beta_prcp)
qqnorm(bootstrap_results_df[, "log_product"], main = "QQ-Plot of log(beta_tmin * beta_prcp)")
qqline(bootstrap_results_df[, "log_product"], col = 'red')
```

![](p8105_hw6_xl3214_files/figure-gfm/Q2-bootstrap%20sampling%20and%20plot-4.png)<!-- -->

### R-square

Based on the histogram, the distribution of R-square appears to be
unimodal and symmetric, centered around 0.90. The shape of the histogram
suggests that most bootstrap samples resulted in R-square values close
to this central value, indicating consistent performance of the
regression model across bootstrap samples. Based on the qq-plot, The
slight deviation at the upper tail (top-right part of the plot) might
indicate a minor departure from normality, with the bootstrap R-square
values being slightly higher than what would be expected under a perfect
normal distribution.

### log(β_tmin x β_prcp)

Based on the histogram, the distribution is unimodel and slightly skewed
to the left, indicating that the log-transformed product of the
coefficients tends to have an inconsistent estimate across bootstrap
samples.qq-plot shows apparent deviation from the line at both tails,
particularly the lower tail, suggests that the log-transformed product
might have a distribution with heavier tails than the normal
distribution, indicating some outliers or extreme values.

``` r
# Calculate mean R-squared and log_product
mean_r_squared <- mean(bootstrap_results_df[, "r_squared"], na.rm = TRUE)
mean_log_product <- mean(bootstrap_results_df[, "log_product"], na.rm = TRUE)

# Create a new data frame that contains the estimates and the confidence intervals
r_squared_results <- data.frame(
  term = "R-squared",
  estimate = mean_r_squared,
  `2.5%` = quantile(bootstrap_results_df[, "r_squared"], probs = 0.025, na.rm = TRUE),
  `97.5%` = quantile(bootstrap_results_df[, "r_squared"], probs = 0.975, na.rm = TRUE), 
  row.names = NULL) |>
  select(term, estimate, X2.5., X97.5.)

log_product_results <- data.frame(
  term = "log(β_tmin * β_prcp)",
  estimate = mean_log_product,
  `2.5%` = quantile(bootstrap_results_df[, "log_product"], probs = 0.025, na.rm = TRUE),
  `97.5%` = quantile(bootstrap_results_df[, "log_product"], probs = 0.975, na.rm = TRUE), 
  row.names = NULL) |>
  select(term, estimate, X2.5., X97.5.)

# Combine the results into one data frame
combined_results <- rbind(r_squared_results, log_product_results) |> 
  rename(lower_ci = X2.5., upper_ci = X97.5.)

# Output the table with knitr::kable
knitr::kable(caption = "95% Confidence Intervals and Estimates", combined_results)
```

| term                  |   estimate |   lower_ci |   upper_ci |
|:----------------------|-----------:|-----------:|-----------:|
| R-squared             |  0.9173027 |  0.8882079 |  0.9402552 |
| log(β_tmin \* β_prcp) | -6.1059669 | -9.0632139 | -4.6192674 |

95% Confidence Intervals and Estimates

## Problem 3: Predictors for Children’s Birthweight

### Data Description

``` r
q3_raw <- read.csv(file = "https://p8105.com/data/birthweight.csv")
```

There are 20 variables and 4342 observations in the dataset. Variable
descriptions as below:

- *babysex*: baby’s sex (male = 1, female = 2)
- *bhead*: baby’s head circumference at birth (cm)
- *blength*: baby’s length at birth (cm)
- *bwt*: baby’s birth weight (grams)
- *delwt*: mother’s weight at delivery (pounds)
- *fincome*: family monthly income (in hundreds, rounded)
- *frace*: father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto
  Rican, 8 = Other, 9 = Unknown)
- *gaweeks*: gestational age in weeks
- *malform*: presence of malformations that could affect weight (0 =
  absent, 1 = present)
- *menarche*: mother’s age at menarche (years)
- *mheigth*: mother’s height (inches)
- *momage*: mother’s age at delivery (years)
- *mrace*: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto
  Rican, 8 = Other)
- *parity*: number of live births prior to this pregnancy
- *pnumlbw*: previous number of low birth weight babies
- *pnumgsa*: number of prior small for gestational age babies
- *ppbmi*: mother’s pre-pregnancy BMI
- *ppwt*: mother’s pre-pregnancy weight (pounds)
- *smoken*: average number of cigarettes smoked per day during pregnancy
- *wtgain*: mother’s weight gain during pregnancy (pounds)

``` r
na_check <- sum(is.na(q3_raw)) # No NAs in the dataset

data_class_check <- summary(q3_raw) # variables are either of class `int` or `num`.

# checking for any missing entries within each column
sapply(q3_raw, function(x) sum(is.na(x)))
```

    ##  babysex    bhead  blength      bwt    delwt  fincome    frace  gaweeks 
    ##        0        0        0        0        0        0        0        0 
    ##  malform menarche  mheight   momage    mrace   parity  pnumlbw  pnumsga 
    ##        0        0        0        0        0        0        0        0 
    ##    ppbmi     ppwt   smoken   wtgain 
    ##        0        0        0        0

``` r
# No NAs found.

# I was thinking some missing entries could have 0 as its placeholder. 
sapply(q3_raw, function(x) sum(x == 0, na.rm = TRUE))
```

    ##  babysex    bhead  blength      bwt    delwt  fincome    frace  gaweeks 
    ##        0        0        0        0        0        1        0        0 
    ##  malform menarche  mheight   momage    mrace   parity  pnumlbw  pnumsga 
    ##     4327        1        0        0        0     4339     4342     4342 
    ##    ppbmi     ppwt   smoken   wtgain 
    ##        0        0     2552       19

``` r
# Variables with 0 in its entries seem reasonable. I would conclude that there is no missing entries in this dataset. 
```

In order to prepare the dataset for regression analysis, categorical
variables need to be turned into class `factor`. Based on the variable
descriptions, categorical variables include: *babysex*, *frace*,
*malform*, *mrace*.

``` r
q3_for_analysis <- q3_raw |>
  mutate(babysex = as.factor(babysex), 
         frace = as.factor(frace), 
         malform = as.factor(malform), 
         mrace = as.factor(mrace))
```

### Model Fitting

For model predictor selection, I will employ a data-driven
model-building process in which step-wise predictor selection is
performed. I will first create a full model that includes all
predictors, then use `step()` function to add or drop predictors one at
a time based on Akaike Information Criterion (AIC).

AIC is a measure of the relative quality of statistical models for a
given set of data. It estimates the information loss when using a model
to represent the process that generated the data. It deals with the
trade-off between the goodness of fit of the model and the complexity of
the model. A lower AIC value indicates a better model. AIC is calculated
as: `AIC=2k−2ln(L)`, where `k` is the number of parameters in the model
and `L` is the maximum value of the likelihood function for the model.
During model selection, the goal is to minimize the AIC; the model with
the lowest AIC is generally preferred.

``` r
full_model <- lm(bwt ~ ., data = q3_for_analysis)
stepwise_model <- step(full_model, direction = "both")
```

    ## Start:  AIC=48717.83
    ## bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + 
    ##     malform + menarche + mheight + momage + mrace + parity + 
    ##     pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain
    ## 
    ## 
    ## Step:  AIC=48717.83
    ## bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + 
    ##     malform + menarche + mheight + momage + mrace + parity + 
    ##     pnumlbw + pnumsga + ppbmi + ppwt + smoken
    ## 
    ## 
    ## Step:  AIC=48717.83
    ## bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + 
    ##     malform + menarche + mheight + momage + mrace + parity + 
    ##     pnumlbw + ppbmi + ppwt + smoken
    ## 
    ## 
    ## Step:  AIC=48717.83
    ## bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + 
    ##     malform + menarche + mheight + momage + mrace + parity + 
    ##     ppbmi + ppwt + smoken
    ## 
    ##            Df Sum of Sq       RSS   AIC
    ## - frace     4    124365 320848704 48712
    ## - malform   1      1419 320725757 48716
    ## - ppbmi     1      6346 320730684 48716
    ## - momage    1     28661 320752999 48716
    ## - mheight   1     66886 320791224 48717
    ## - menarche  1    111679 320836018 48717
    ## - ppwt      1    131132 320855470 48718
    ## <none>                  320724338 48718
    ## - fincome   1    193454 320917792 48718
    ## - parity    1    413584 321137922 48721
    ## - mrace     3    868321 321592659 48724
    ## - babysex   1    853796 321578134 48727
    ## - gaweeks   1   4611823 325336161 48778
    ## - smoken    1   5076393 325800732 48784
    ## - delwt     1   8008891 328733230 48823
    ## - blength   1 102050296 422774634 49915
    ## - bhead     1 106535716 427260054 49961
    ## 
    ## Step:  AIC=48711.51
    ## bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    ##     malform + menarche + mheight + momage + mrace + parity + 
    ##     ppbmi + ppwt + smoken
    ## 
    ##            Df Sum of Sq       RSS   AIC
    ## - malform   1      1447 320850151 48710
    ## - ppbmi     1      6975 320855679 48710
    ## - momage    1     28379 320877083 48710
    ## - mheight   1     69502 320918206 48710
    ## - menarche  1    115708 320964411 48711
    ## - ppwt      1    133961 320982665 48711
    ## <none>                  320848704 48712
    ## - fincome   1    194405 321043108 48712
    ## - parity    1    414687 321263390 48715
    ## + frace     4    124365 320724338 48718
    ## - babysex   1    852133 321700837 48721
    ## - gaweeks   1   4625208 325473911 48772
    ## - smoken    1   5036389 325885093 48777
    ## - delwt     1   8013099 328861802 48817
    ## - mrace     3  13540415 334389119 48885
    ## - blength   1 101995688 422844392 49908
    ## - bhead     1 106662962 427511666 49956
    ## 
    ## Step:  AIC=48709.53
    ## bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    ##     menarche + mheight + momage + mrace + parity + ppbmi + ppwt + 
    ##     smoken
    ## 
    ##            Df Sum of Sq       RSS   AIC
    ## - ppbmi     1      6928 320857079 48708
    ## - momage    1     28660 320878811 48708
    ## - mheight   1     69320 320919470 48708
    ## - menarche  1    116027 320966177 48709
    ## - ppwt      1    133894 320984044 48709
    ## <none>                  320850151 48710
    ## - fincome   1    193784 321043934 48710
    ## + malform   1      1447 320848704 48712
    ## - parity    1    414482 321264633 48713
    ## + frace     4    124393 320725757 48716
    ## - babysex   1    851279 321701430 48719
    ## - gaweeks   1   4624003 325474154 48770
    ## - smoken    1   5035195 325885346 48775
    ## - delwt     1   8029079 328879230 48815
    ## - mrace     3  13553320 334403471 48883
    ## - blength   1 102009225 422859375 49906
    ## - bhead     1 106675331 427525481 49954
    ## 
    ## Step:  AIC=48707.63
    ## bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    ##     menarche + mheight + momage + mrace + parity + ppwt + smoken
    ## 
    ##            Df Sum of Sq       RSS   AIC
    ## - momage    1     29211 320886290 48706
    ## - menarche  1    117635 320974714 48707
    ## <none>                  320857079 48708
    ## - fincome   1    195199 321052278 48708
    ## + ppbmi     1      6928 320850151 48710
    ## + malform   1      1400 320855679 48710
    ## - parity    1    412984 321270064 48711
    ## + frace     4    125020 320732060 48714
    ## - babysex   1    850020 321707099 48717
    ## - mheight   1   1078673 321935752 48720
    ## - ppwt      1   2934023 323791103 48745
    ## - gaweeks   1   4621504 325478583 48768
    ## - smoken    1   5039368 325896447 48773
    ## - delwt     1   8024939 328882018 48813
    ## - mrace     3  13551444 334408523 48881
    ## - blength   1 102018559 422875638 49904
    ## - bhead     1 106821342 427678421 49953
    ## 
    ## Step:  AIC=48706.02
    ## bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    ##     menarche + mheight + mrace + parity + ppwt + smoken
    ## 
    ##            Df Sum of Sq       RSS   AIC
    ## - menarche  1    100121 320986412 48705
    ## <none>                  320886290 48706
    ## - fincome   1    240800 321127090 48707
    ## + momage    1     29211 320857079 48708
    ## + ppbmi     1      7479 320878811 48708
    ## + malform   1      1678 320884612 48708
    ## - parity    1    431433 321317724 48710
    ## + frace     4    124743 320761547 48712
    ## - babysex   1    841278 321727568 48715
    ## - mheight   1   1076739 321963029 48719
    ## - ppwt      1   2913653 323799943 48743
    ## - gaweeks   1   4676469 325562760 48767
    ## - smoken    1   5045104 325931394 48772
    ## - delwt     1   8000672 328886962 48811
    ## - mrace     3  14667730 335554021 48894
    ## - blength   1 101990556 422876847 49902
    ## - bhead     1 106864308 427750598 49952
    ## 
    ## Step:  AIC=48705.38
    ## bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    ##     mheight + mrace + parity + ppwt + smoken
    ## 
    ##            Df Sum of Sq       RSS   AIC
    ## <none>                  320986412 48705
    ## + menarche  1    100121 320886290 48706
    ## - fincome   1    245637 321232048 48707
    ## + momage    1     11698 320974714 48707
    ## + ppbmi     1      8823 320977589 48707
    ## + malform   1      1884 320984528 48707
    ## - parity    1    422770 321409181 48709
    ## + frace     4    128726 320857686 48712
    ## - babysex   1    846134 321832545 48715
    ## - mheight   1   1012240 321998651 48717
    ## - ppwt      1   2907049 323893461 48743
    ## - gaweeks   1   4662501 325648912 48766
    ## - smoken    1   5073849 326060260 48771
    ## - delwt     1   8137459 329123871 48812
    ## - mrace     3  14683609 335670021 48894
    ## - blength   1 102191779 423178191 49903
    ## - bhead     1 106779754 427766166 49950

``` r
summary(stepwise_model)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    ##     gaweeks + mheight + mrace + parity + ppwt + smoken, data = q3_for_analysis)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1097.18  -185.52    -3.39   174.14  2353.44 
    ## 
    ## Coefficients:
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) -6098.8219   137.5463 -44.340  < 2e-16 ***
    ## babysex2       28.5580     8.4549   3.378 0.000737 ***
    ## bhead         130.7770     3.4466  37.944  < 2e-16 ***
    ## blength        74.9471     2.0190  37.120  < 2e-16 ***
    ## delwt           4.1067     0.3921  10.475  < 2e-16 ***
    ## fincome         0.3180     0.1747   1.820 0.068844 .  
    ## gaweeks        11.5925     1.4621   7.929 2.79e-15 ***
    ## mheight         6.5940     1.7849   3.694 0.000223 ***
    ## mrace2       -138.7925     9.9071 -14.009  < 2e-16 ***
    ## mrace3        -74.8868    42.3146  -1.770 0.076837 .  
    ## mrace4       -100.6781    19.3247  -5.210 1.98e-07 ***
    ## parity         96.3047    40.3362   2.388 0.017004 *  
    ## ppwt           -2.6756     0.4274  -6.261 4.20e-10 ***
    ## smoken         -4.8434     0.5856  -8.271  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.3 on 4328 degrees of freedom
    ## Multiple R-squared:  0.7181, Adjusted R-squared:  0.7173 
    ## F-statistic: 848.1 on 13 and 4328 DF,  p-value: < 2.2e-16

``` r
tidy_summary <- tidy(stepwise_model)
knitr::kable(tidy_summary, format = "html", caption = "Summary of Stepwise Model")
```

<table>
<caption>
Summary of Stepwise Model
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
-6098.8219113
</td>
<td style="text-align:right;">
137.5463421
</td>
<td style="text-align:right;">
-44.340124
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
babysex2
</td>
<td style="text-align:right;">
28.5580171
</td>
<td style="text-align:right;">
8.4548958
</td>
<td style="text-align:right;">
3.377690
</td>
<td style="text-align:right;">
0.0007374
</td>
</tr>
<tr>
<td style="text-align:left;">
bhead
</td>
<td style="text-align:right;">
130.7770408
</td>
<td style="text-align:right;">
3.4465672
</td>
<td style="text-align:right;">
37.944144
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
blength
</td>
<td style="text-align:right;">
74.9471109
</td>
<td style="text-align:right;">
2.0190479
</td>
<td style="text-align:right;">
37.120027
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
delwt
</td>
<td style="text-align:right;">
4.1067316
</td>
<td style="text-align:right;">
0.3920592
</td>
<td style="text-align:right;">
10.474775
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
fincome
</td>
<td style="text-align:right;">
0.3180229
</td>
<td style="text-align:right;">
0.1747477
</td>
<td style="text-align:right;">
1.819898
</td>
<td style="text-align:right;">
0.0688436
</td>
</tr>
<tr>
<td style="text-align:left;">
gaweeks
</td>
<td style="text-align:right;">
11.5924873
</td>
<td style="text-align:right;">
1.4620657
</td>
<td style="text-align:right;">
7.928842
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
mheight
</td>
<td style="text-align:right;">
6.5940377
</td>
<td style="text-align:right;">
1.7848817
</td>
<td style="text-align:right;">
3.694383
</td>
<td style="text-align:right;">
0.0002231
</td>
</tr>
<tr>
<td style="text-align:left;">
mrace2
</td>
<td style="text-align:right;">
-138.7924801
</td>
<td style="text-align:right;">
9.9070869
</td>
<td style="text-align:right;">
-14.009414
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
mrace3
</td>
<td style="text-align:right;">
-74.8867755
</td>
<td style="text-align:right;">
42.3146313
</td>
<td style="text-align:right;">
-1.769761
</td>
<td style="text-align:right;">
0.0768374
</td>
</tr>
<tr>
<td style="text-align:left;">
mrace4
</td>
<td style="text-align:right;">
-100.6781427
</td>
<td style="text-align:right;">
19.3246910
</td>
<td style="text-align:right;">
-5.209819
</td>
<td style="text-align:right;">
0.0000002
</td>
</tr>
<tr>
<td style="text-align:left;">
parity
</td>
<td style="text-align:right;">
96.3046933
</td>
<td style="text-align:right;">
40.3362158
</td>
<td style="text-align:right;">
2.387549
</td>
<td style="text-align:right;">
0.0170038
</td>
</tr>
<tr>
<td style="text-align:left;">
ppwt
</td>
<td style="text-align:right;">
-2.6755853
</td>
<td style="text-align:right;">
0.4273585
</td>
<td style="text-align:right;">
-6.260752
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
smoken
</td>
<td style="text-align:right;">
-4.8434197
</td>
<td style="text-align:right;">
0.5855757
</td>
<td style="text-align:right;">
-8.271210
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
</tbody>
</table>

Based on the output, variables selected to the final model include:
(Intercept), babysex2, bhead, blength, delwt, fincome, gaweeks, mheight,
mrace2, mrace3, mrace4, parity, ppwt, smoken. The model has a residual
standard error of 272.3 on 4328 degrees of freedom, Multiple R-squared
of 0.7181, and F-statistic of 848.1 on 13 and 4328 DF, p-value: \<
2.2e-16.

The selected variables in the final model are statistically significant
predictors of baby’s birth weight. The high R-squared indicates the
model explains a substantial portion of the variation in birth weight,
suggesting a strong relationship between predictors and birth weight.

### Model Diagnostics & Assumption Check

Linear regression has many assumptions:

1.  **Linearity:** check by plotting the fitted values against the
    residuals and see if the plot shows a random scatter.
2.  **Independence:** check using the Durbin-Watson test; values close
    to 2 suggest independence.
3.  **Homoscedasticity:** check using the same fitted values against
    residuals plot to see if there is a constant spread of residuals
    across all levels of fitted values.
4.  **Normal distribution of residuals:** A Q-Q plot of residuals will
    be used to assess whether the residuals are normally distributed. If
    points fall approximately along a straight line, the residuals are
    normally distributed.
5.  Additionally, with multiple predictors, potential
    **multicollinearity** also needs to be checked, as it can affect the
    stability and interpretation of regression coefficients. I will use
    the Variance Inflation Factor (VIF) and Durbin-Watson test to check
    for multicollinearity.

``` r
# Residuals vs Fitted Plot
augmented_data <- q3_for_analysis |>
  add_predictions(stepwise_model, var = "fitted_values") |>
  add_residuals(stepwise_model, var = "residuals")

ggplot(augmented_data, aes(x = fitted_values, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Fitted Values", y = "Residuals", title = "Residuals vs Fitted Values Plot") +
  theme_minimal()
```

![](p8105_hw6_xl3214_files/figure-gfm/q3-model%20diagnostics-1.png)<!-- -->

``` r
# Normal Q-Q Plot
qqnorm(residuals(stepwise_model))
qqline(residuals(stepwise_model), col = "red")
```

![](p8105_hw6_xl3214_files/figure-gfm/q3-model%20diagnostics-2.png)<!-- -->

``` r
# VIF to check for multicollinearity
vif(stepwise_model)
```

    ##             GVIF Df GVIF^(1/(2*Df))
    ## babysex 1.045505  1        1.022499
    ## bhead   1.826019  1        1.351303
    ## blength 1.769732  1        1.330313
    ## delwt   4.437162  1        2.106457
    ## fincome 1.205999  1        1.098180
    ## gaweeks 1.245075  1        1.115829
    ## mheight 1.315871  1        1.147114
    ## mrace   1.439897  3        1.062646
    ## parity  1.008629  1        1.004305
    ## ppwt    4.345209  1        2.084516
    ## smoken  1.101300  1        1.049428

``` r
# Durbin-Watson test for independence of errors
dwtest(stepwise_model)
```

    ## 
    ##  Durbin-Watson test
    ## 
    ## data:  stepwise_model
    ## DW = 1.9238, p-value = 0.005625
    ## alternative hypothesis: true autocorrelation is greater than 0

1.  **Linearity:** The Residuals vs Fitted plot shows a random scatter
    of residuals across the range of fitted values, indicating
    linearity.
2.  **Independence:** The Durbin-Watson test result (DW = 1.9238) is
    close to 2, which suggests that there is not strong evidence of
    autocorrelation in the residuals. However, the p-value is
    significant (0.005625), indicating some level of positive
    autocorrelation, although this may not be substantial enough to
    seriously violate the independence assumption.
3.  **Homoscedasticity:** The Residuals vs Fitted plot shows a
    relatively stable variance of residuals as fitted values increase.
    There is a slight funnel shape observed, but it is very minimal and
    should not be of severe concern.
4.  **Normal distribution of residuals:** Q-Q plot shows that the
    residuals aligns with the line overall with slight deviation at the
    ends, indicating that the residuals are approximately normally
    distributed with some potential extreme values, but are not
    warranting violation of residual normal distribution assumption.
5.  **Multicollinearity:** VIF values greater than 10 warrants concerns
    of multicollinearity. None of the VIF values for my model are
    greater than 10, indicating no serious multicollinearity issues.
