---
title: "p8105_hw6_xl3214"
author: "Xuan Lu"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load necessary packages, echo=FALSE, message=FALSE}
library(dplyr)
library(tidyr)
library(purrr)
library(forcats)
library(ggplot2)
library(broom)
library(modelr)
library(car)
library(lmtest)
```

## Problem 1: The Homocide Dataset by Washington Post

### Step 1: Data Import and Preparation for Analysis

```{r Q1-data import}
q1_raw <- read.csv(file = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv", 
                   na = c("", "NA", "Unknown"))
```

The raw data has `r ncol(q1_raw)` variables and `r nrow(q1_raw)` observations. Variables include: *`r colnames(q1_raw)`*.

```{r Q1-data cleaning and manipulation for analysis}
q1_for_analysis <- q1_raw |>
  # Create city_state variable in the format of "City, State"
  mutate(city_state = paste(city, state, sep = ", "), 
         # victim_age needs to be numeric
         victim_age = as.numeric(victim_age), 
         # Create binary variable indicating whether the homicide is solved
         resolved = factor(ifelse(disposition == "Closed by arrest", 1, 0),
                           levels = c(0, 1),
                           labels = c("No", "Yes"),
                           ordered = TRUE)) |>
  # Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race
  # Omit Tulsa, AL – this is a data entry mistake
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) |>
  # Limit analysis to victim_race is white or black
  filter(victim_race %in% c("White", "Black")) |>
  select(city_state, resolved, victim_age, victim_sex, victim_race)
```

After data cleaning and validation, which excludes cities Dallas, TX; Phoenix, AZ; Kansas City, MO; and Tulsa, AL, and limiting the victim_race to only black or white, the dataset pertained to analysis stage includes `r ncol(q1_for_analysis)` variables and `r nrow(q1_for_analysis)` observations. 

### Step 2: Fit Logistic Regression for Baltimore, MD

Fit a logistic regression model for the city of Baltimore, MD using `glm()`, with the binary variable indicating whether the homicide is solved as the outcome, and victim age, sex, and race as predictors. Use `broom::tidy()` to extract the model estimates and confidence intervals, focusing on the adjusted odds ratio for male vs. female victims.

```{r Q1-glm model of baltimore}
model_baltimore <- q1_for_analysis |>
  # Filter the dataset to include only rows where city_state is "Baltimore, MD"
  filter(city_state == "Baltimore, MD") |>
  # Fit a logistic regression model with resolved as the response variable and victim_age, victim_sex, and victim_race as predictors
  glm(resolved ~ victim_age + victim_sex + victim_race, 
                       data = _, family = "binomial") |>
  # Use broom::tidy to convert the glm model object into a tidy dataframe and calculate confidence intervals
  broom::tidy(conf.int = TRUE) |>
  # Filter the results to keep only the row for the term "victim_sexMale"
  filter(term == "victim_sexMale") |>
  # Calculate the odds ratio and its confidence intervals by exponentiating the estimates
  mutate(OR = exp(estimate),
         OR_lower_ci = exp(conf.low),
         OR_upper_ci = exp(conf.high),
         p_value = p.value) |>
  # Select only the relevant columns for the final output
  select(term, OR, OR_lower_ci, OR_upper_ci, p_value)
```

The odds of the homicide being solved for male victims is estimated to be `r pull(model_baltimore, OR)` times that of female victims, adjusting for victim age and race. A reasonable (alpha = 0.05)
range of estimates for the true OR is between `r pull(model_baltimore, OR_lower_ci)` and `r pull(model_baltimore, OR_upper_ci)`. 
The p-value is `r pull(model_baltimore, p_value)`, indicating `r if (pull(model_baltimore, p_value) < 0.05) "a statistically significant association between victim's sex and the resolution of the homicide" else "the association between victim's sex and the resolution of the homicide is not statistically significant"`.

### Step 3: Logistic Regression for Each City and Dataframe with Estimated ORs and CIs

Apply `glm()` to each city in the dataset to get the adjusted odds ratio for male vs. female victims using `tidyverse::nest()`, `purrr::map()`, and `tidyverse::unnest()`.

```{r Q1-glm model for all cities in dataset}
model_all_cities <- q1_for_analysis |>
  # the data is being grouped by city_state and stored in "data"
  nest(data = -city_state) |>
  # fit the glm model for each nested dataframe
  mutate(models = map(data, ~glm(resolved ~ victim_age + victim_sex + victim_race, 
                                 family = "binomial", data = .))) |>
  # tidy the glm models and calculate ORs and CIs
  mutate(tidy_models = map(models, ~broom::tidy(.x, conf.int = TRUE))) |>
  # extract only the rows corresponding to the term "victim_sexMale"
  mutate(tidy_models = map(tidy_models, ~filter(.x, term == "victim_sexMale"))) |>
  # calculate the odds ratios and confidence intervals
  mutate(tidy_models = map(tidy_models, ~mutate(.x, 
                                                OR = exp(estimate),
                                                OR_lower_ci = exp(conf.low),
                                                OR_upper_ci = exp(conf.high), 
                                                p_value = p.value))) |>
  # remove the columns that are no longer needed
  select(-data, -models) |>
  # unnest the tidy_models to get a flat dataframe
  unnest(cols = tidy_models) |>
  # select the final columns of interest
  select(city_state, term, OR, OR_lower_ci, OR_upper_ci, p_value)

model_all_cities |>
  arrange(desc(OR)) |> 
  slice(1:5) |>
  knitr::kable(digits = 3)
```
Based on the output table, Albuquerque, NM has the highest odds ratio when comparing victims whose sex is male to those whose sex is female. With a p-value of 0.139, however, we do not have sufficient evidence to conclude that the odds of resolving the homicide is statistically higher among males than females in Albuquerque, NM, after adjusting for victim age and race. 

### Step 4: Plotting the Results

```{r Q1-plotting of ORs for all cities, fig.height=10, fig.width=8}
# Start with the model_all_cities dataset
model_all_cities |> 
  # Initialize a ggplot with city_state on the x-axis and OR on the y-axis. Cities are reordered by OR for a meaningful display.
  ggplot(aes(x = fct_reorder(city_state, OR), y = OR)) +
  # Add points to the plot for each city's OR value.
  geom_point() +
  # Add vertical error bars for each point to represent the confidence interval of the OR, with a specified width.
  geom_errorbar(aes(ymin = OR_lower_ci, ymax = OR_upper_ci), width = 0.2) +
  # Flip the coordinates to have cities on the y-axis and OR on the x-axis for easier reading of long city names.
  coord_flip() +
  # Add labels to the x and y axes, and a title to the plot.
  labs(x = "City", y = "Odds Ratio (Male vs Female Victims, reference = Female)",
       title = "Adjusted Odds Ratios for Solving Homicides by City")
```


## Problem 2: NYC Central Park Weather

In this problem, bootstrap is being used to understand the distribution and confidence intervals of certain statistical quantities derived from a linear regression model. These quantities are R-square and log(β_tmin x β_prcp). Since the exact distribution of these quantities might not be easily derivable from theoretical principles, especially when dealing with real-world data like weather statistics, bootstrapping provides a way to empirically estimate their distribution.

Meaning of R-square: In regression analysis, R-square is a measure of how well the regression predictions approximate the real data points. In this case, how well tmax can be predicted from tmin and prcp. A R-square close to 1 indicates that the regression model explains a large portion of the variance in the response variable.

Meaning of log(β_tmin x β_prcp): The coefficients are likely the estimated coefficients for tmin and prcp in predicting tmax. The product β_tmin x β_prcp would be an interaction term, and taking the logarithm of this product could be a way to interpret the combined effect of these predictors on the logarithmic scale (therefore assess interaction on multiplicative scale).

By using bootstrapping to estimate the distribution of these quantities, we can gain insights into the uncertainty and variability associated with our regression model's predictions and the interaction of the predictors in the model. 

```{r Q2-retrieve data}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```
### Steps: 

- **Bootstrap Sampling:** Generate 5000 bootstrap samples of the dataset.
- **Fit Linear Regression:** For each sample, fit a linear regression model with *tmax* as the response variable and *tmin* and *prcp* as the predictors.
- **Extract R-square:** Use `broom::glance()` to extract the R-square value from each fitted model.
- **Calculate log(β_tmin x β_prcp):** Use `broom::tidy()` to get the regression coefficients from each model, then calculate the log product of the *tmin* and *prcp* coefficients.
- **Plot Distributions:** Plot the distributions of the 5000 R-square values and the 5000 log(β_hat_1 * β_hat_2) values.
- **Calculate Confidence Intervals:** Determine the 2.5th and 97.5th percentiles of the bootstrap estimates to find the 95% confidence intervals for both statistics.

```{r Q2-bootstrap sampling and plot}
set.seed(123)  # For reproducibility of bootstrap samples

# Define the bootstrap function
bootstrap_sample <- function(df) {
  sample_indices <- sample(seq_len(nrow(df)), size = nrow(df), replace = TRUE)
  sample_df <- df[sample_indices, ]
  
  fit <- lm(tmax ~ tmin + prcp, data = sample_df)
  glance_stats <- glance(fit)
  tidy_stats <- tidy(fit)
  
  # Extract R-squared
  r_squared <- pull(glance_stats, r.squared)
  
  # Compute the log product of tmin and prcp coefficients
  coef_tmin <- tidy_stats |>
  filter(term == "tmin") |>
  pull(estimate)

  coef_prcp <- tidy_stats |>
  filter(term == "prcp") |>
  pull(estimate)
  
  # Handle cases where the product might be non-positive using log1p, which calculates log(1 + x)
  log_product <- ifelse(coef_tmin * coef_prcp > 0, log(coef_tmin * coef_prcp), NA)
  
  return(list(r_squared = r_squared, log_product = log_product))
}

# Generate bootstrap samples and compute statistics for each
bootstrap_results <- replicate(5000, bootstrap_sample(weather_df), simplify = FALSE) 
# Convert the list of bootstrap results into a data frame
bootstrap_results_df <- do.call(rbind.data.frame, bootstrap_results)

# Histogram of R^2
hist(bootstrap_results_df[, "r_squared"], main = "Histogram of R^2", 
     xlab = "R^2", breaks = 20, col = 'blue')

# QQ-plot of R^2
qqnorm(bootstrap_results_df[, "r_squared"], main = "QQ-Plot of R^2")
qqline(bootstrap_results_df[, "r_squared"], col = 'red')

# Histogram of log(beta_tmin * beta_prcp)
hist(bootstrap_results_df[, "log_product"], main = "Histogram of log(beta_tmin * beta_prcp)", 
     xlab = "log(beta_tmin * beta_prcp)", breaks = 20, col = 'blue')

# QQ-plot of log(beta_tmin * beta_prcp)
qqnorm(bootstrap_results_df[, "log_product"], main = "QQ-Plot of log(beta_tmin * beta_prcp)")
qqline(bootstrap_results_df[, "log_product"], col = 'red')
```

### R-square

Based on the histogram, the distribution of R-square appears to be unimodal and symmetric, centered around 0.90. The shape of the histogram suggests that most bootstrap samples resulted in R-square values close to this central value, indicating consistent performance of the regression model across bootstrap samples. Based on the qq-plot, The slight deviation at the upper tail (top-right part of the plot) might indicate a minor departure from normality, with the bootstrap R-square values being slightly higher than what would be expected under a perfect normal distribution.

### log(β_tmin x β_prcp)

Based on the histogram, the distribution is unimodel and slightly skewed to the left, indicating that the log-transformed product of the coefficients tends to have an inconsistent estimate across bootstrap samples.qq-plot shows apparent deviation from the line at both tails, particularly the lower tail, suggests that the log-transformed product might have a distribution with heavier tails than the normal distribution, indicating some outliers or extreme values.

```{r Q2-calculate 95% CI}
# Calculate mean R-squared and log_product
mean_r_squared <- mean(bootstrap_results_df[, "r_squared"], na.rm = TRUE)
mean_log_product <- mean(bootstrap_results_df[, "log_product"], na.rm = TRUE)

# Create a new data frame that contains the estimates and the confidence intervals
r_squared_results <- data.frame(
  term = "R-squared",
  estimate = mean_r_squared,
  `2.5%` = quantile(bootstrap_results_df[, "r_squared"], probs = 0.025, na.rm = TRUE),
  `97.5%` = quantile(bootstrap_results_df[, "r_squared"], probs = 0.975, na.rm = TRUE), 
  row.names = NULL) |>
  select(term, estimate, X2.5., X97.5.)

log_product_results <- data.frame(
  term = "log(β_tmin * β_prcp)",
  estimate = mean_log_product,
  `2.5%` = quantile(bootstrap_results_df[, "log_product"], probs = 0.025, na.rm = TRUE),
  `97.5%` = quantile(bootstrap_results_df[, "log_product"], probs = 0.975, na.rm = TRUE), 
  row.names = NULL) |>
  select(term, estimate, X2.5., X97.5.)

# Combine the results into one data frame
combined_results <- rbind(r_squared_results, log_product_results) |> 
  rename(lower_ci = X2.5., upper_ci = X97.5.)

# Output the table with knitr::kable
knitr::kable(caption = "95% Confidence Intervals and Estimates", combined_results)
```

## Problem 3: Predictors for Children's Birthweight

### Data Description

```{r q3-import data}
q3_raw <- read.csv(file = "https://p8105.com/data/birthweight.csv")
```

There are `r ncol(q3_raw)` variables and `r nrow(q3_raw)` observations in the dataset. Variable descriptions as below: 

- *babysex*: baby’s sex (male = 1, female = 2)
- *bhead*: baby’s head circumference at birth (cm)
- *blength*: baby’s length at birth (cm)
- *bwt*: baby’s birth weight (grams)
- *delwt*: mother’s weight at delivery (pounds)
- *fincome*: family monthly income (in hundreds, rounded)
- *frace*: father’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other, 9 = Unknown)
- *gaweeks*: gestational age in weeks
- *malform*: presence of malformations that could affect weight (0 = absent, 1 = present)
- *menarche*: mother’s age at menarche (years)
- *mheigth*: mother’s height (inches)
- *momage*: mother’s age at delivery (years)
- *mrace*: mother’s race (1 = White, 2 = Black, 3 = Asian, 4 = Puerto Rican, 8 = Other)
- *parity*: number of live births prior to this pregnancy
- *pnumlbw*: previous number of low birth weight babies
- *pnumgsa*: number of prior small for gestational age babies
- *ppbmi*: mother’s pre-pregnancy BMI
- *ppwt*: mother’s pre-pregnancy weight (pounds)
- *smoken*: average number of cigarettes smoked per day during pregnancy
- *wtgain*: mother’s weight gain during pregnancy (pounds)

```{r q3-data quality check}
na_check <- sum(is.na(q3_raw)) # No NAs in the dataset

data_class_check <- summary(q3_raw) # variables are either of class `int` or `num`.

# checking for any missing entries within each column
sapply(q3_raw, function(x) sum(is.na(x)))
# No NAs found.

# I was thinking some missing entries could have 0 as its placeholder. 
sapply(q3_raw, function(x) sum(x == 0, na.rm = TRUE))
# Variables with 0 in its entries seem reasonable. I would conclude that there is no missing entries in this dataset. 
```

In order to prepare the dataset for regression analysis, categorical variables need to be turned into class `factor`. Based on the variable descriptions, categorical variables include: *babysex*, *frace*, *malform*, *mrace*.

```{r q3-data preparation for regression analysis}
q3_for_analysis <- q3_raw |>
  mutate(babysex = as.factor(babysex), 
         frace = as.factor(frace), 
         malform = as.factor(malform), 
         mrace = as.factor(mrace))
```

### Model Fitting

For model predictor selection, I will employ a data-driven model-building process in which step-wise predictor selection is performed. I will first create a full model that includes all predictors, then use `step()` function to add or drop predictors one at a time based on Akaike Information Criterion (AIC). 

AIC is a measure of the relative quality of statistical models for a given set of data. It estimates the information loss when using a model to represent the process that generated the data. It deals with the trade-off between the goodness of fit of the model and the complexity of the model. A lower AIC value indicates a better model. AIC is calculated as: `AIC=2k−2ln(L)`, where `k` is the number of parameters in the model and `L` is the maximum value of the likelihood function for the model. During model selection, the goal is to minimize the AIC; the model with the lowest AIC is generally preferred.

```{r q3-predictor selection}
full_model <- lm(bwt ~ ., data = q3_for_analysis)
stepwise_model <- step(full_model, direction = "both")
summary(stepwise_model)
tidy_summary <- tidy(stepwise_model)
knitr::kable(tidy_summary, format = "html", caption = "Summary of Stepwise Model")
```

Based on the output, variables selected to the final model include: `r pull(tidy_summary, term)`. The model has a residual standard error of 272.3 on 4328 degrees of freedom, Multiple R-squared of  0.7181, and F-statistic of 848.1 on 13 and 4328 DF,  p-value: < 2.2e-16.

The selected variables in the final model are statistically significant predictors of baby's birth weight. The high R-squared indicates the model explains a substantial portion of the variation in birth weight, suggesting a strong relationship between predictors and birth weight.

### Model Diagnostics & Assumption Check

Linear regression has many assumptions: 

1. **Linearity:** check by plotting the fitted values against the residuals and see if the plot shows a random scatter.
2. **Independence:** check using the Durbin-Watson test; values close to 2 suggest independence.
3. **Homoscedasticity:** check using the same fitted values against residuals plot to see if there is a constant spread of residuals across all levels of fitted values.
4. **Normal distribution of residuals:** A Q-Q plot of residuals will be used to assess whether the residuals are normally distributed. If points fall approximately along a straight line, the residuals are normally distributed.
5. Additionally, with multiple predictors, potential **multicollinearity** also needs to be checked, as it can affect the stability and interpretation of regression coefficients. I will use the Variance Inflation Factor (VIF) and Durbin-Watson test to check for multicollinearity. 

```{r}
# Residuals vs Fitted Plot
augmented_data <- q3_for_analysis |>
  add_predictions(stepwise_model, var = "fitted_values") |>
  add_residuals(stepwise_model, var = "residuals")

ggplot(augmented_data, aes(x = fitted_values, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red") +
  labs(x = "Fitted Values", y = "Residuals", title = "Residuals vs Fitted Values Plot") +
  theme_minimal()

# Normal Q-Q Plot
qqnorm(residuals(stepwise_model))
qqline(residuals(stepwise_model), col = "red")

# VIF to check for multicollinearity
vif(stepwise_model)

# Durbin-Watson test for independence of errors
dwtest(stepwise_model)
```

1. **Linearity:** The Residuals vs Fitted plot shows a random scatter of residuals across the range of fitted values, indicating linearity. 
2. **Independence:** The Durbin-Watson test result (DW = 1.9238) is close to 2, which suggests that there is not strong evidence of autocorrelation in the residuals. However, the p-value is significant (0.005625), indicating some level of positive autocorrelation, although this may not be substantial enough to seriously violate the independence assumption.
3. **Homoscedasticity:** The Residuals vs Fitted plot shows a relatively stable variance of residuals as fitted values increase. There is a slight funnel shape observed, but it is very minimal and should not be of severe concern.
4. **Normal distribution of residuals:** Q-Q plot shows that the residuals aligns with the line overall with slight deviation at the ends, indicating that the residuals are approximately normally distributed with some potential extreme values, but are not warranting violation of residual normal distribution assumption. 
5. **Multicollinearity:** VIF values greater than 10 warrants concerns of multicollinearity. None of the VIF values for my model are greater than 10, indicating no serious multicollinearity issues.


